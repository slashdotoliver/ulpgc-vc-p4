{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c2f3fc7",
   "metadata": {},
   "source": [
    "# 1. Detector de personas y vehículos\n",
    "\n",
    "Para conseguir localizar y hacer seguimiento de personas y vehículos en un vídeo, se utiliza YOLOv11 en su versión *nano* como detector de objetos. Se carga el vídeo de entrada y se configura el modelo con las clases de interés (`person`, `bicycle`, `car` y `bus`) junto con un umbral mínimo de confianza para filtrar detecciones poco fiables.  \n",
    "\n",
    "A medida que se procesan los fotogramas, se generan cuadros delimitadores sobre los objetos detectados y se asigna un identificador de seguimiento único a cada instancia. Esto permite mantener el seguimiento de cada objeto a lo largo del vídeo, incluso cuando puede quedar parcialmente ocluido.  \n",
    "\n",
    "Todas las detecciones y sus características se registran en un archivo CSV, mientras que el vídeo resultante se guarda anotado con los delimitadores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813d2b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "VIDEO_IN = \"videos/C0142.mp4\"\n",
    "PROJECT = \"outputs\"\n",
    "NAME = \"C0142_annotated\"\n",
    "CSV_OUT = \"C0142_tracks.csv\"\n",
    "\n",
    "MODEL_WEIGHTS = \"yolo11n.pt\"\n",
    "TRACKER_CFG = \"botsort.yaml\"\n",
    "CONF_THRESH = 0.25\n",
    "CLASSES = {\"person\", \"bicycle\", \"car\", \"bus\"}\n",
    "\n",
    "model = YOLO(MODEL_WEIGHTS)\n",
    "\n",
    "csv_f = open(CSV_OUT, \"w\", newline=\"\", encoding=\"utf-8\")\n",
    "csv_writer = csv.writer(csv_f)\n",
    "csv_writer.writerow([\"fotograma\", \"tipo_objeto\", \"confianza\", \"identificador_tracking\", \"x1\", \"y1\", \"x2\", \"y2\"])\n",
    "\n",
    "frame_idx = 0\n",
    "stream = model.track(\n",
    "    source=VIDEO_IN,\n",
    "    tracker=TRACKER_CFG,\n",
    "    persist=True,\n",
    "    stream=True,\n",
    "    save=True,\n",
    "    project=PROJECT,\n",
    "    name=NAME\n",
    ")\n",
    "\n",
    "unique_tracks = {k: set() for k in CLASSES}\n",
    "total_detections = {k: 0 for k in CLASSES}\n",
    "\n",
    "for results in stream:\n",
    "    frame_idx += 1\n",
    "    boxes = results.boxes\n",
    "    if boxes is None:\n",
    "        continue\n",
    "\n",
    "    xyxy = boxes.xyxy.cpu().numpy() if hasattr(boxes, \"xyxy\") else []\n",
    "    confs = boxes.conf.cpu().numpy() if hasattr(boxes, \"conf\") else []\n",
    "    cls_ids = boxes.cls.cpu().numpy().astype(int) if hasattr(boxes, \"cls\") else []\n",
    "    try:\n",
    "        ids = boxes.id.cpu().numpy().astype(int)\n",
    "    except Exception:\n",
    "        ids = [-1] * len(xyxy)\n",
    "\n",
    "    names = results.names if hasattr(results, \"names\") else model.names\n",
    "\n",
    "    for i, box in enumerate(xyxy):\n",
    "        conf = float(confs[i])\n",
    "        if conf < CONF_THRESH:\n",
    "            continue\n",
    "        cls_name = names.get(int(cls_ids[i]), str(int(cls_ids[i])))\n",
    "        if cls_name not in CLASSES:\n",
    "            continue\n",
    "        track_id = int(ids[i]) if i < len(ids) else -1\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        identifier = f\"{cls_name}_{track_id}\" if track_id >= 0 else f\"{cls_name}_-1\"\n",
    "\n",
    "        csv_writer.writerow([frame_idx, cls_name, f\"{conf:.4f}\", identifier, x1, y1, x2, y2])\n",
    "\n",
    "        total_detections[cls_name] = total_detections.get(cls_name, 0) + 1\n",
    "        if track_id >= 0:\n",
    "            unique_tracks[cls_name].add(track_id)\n",
    "\n",
    "csv_f.close()\n",
    "\n",
    "print(\"Resumen:\")\n",
    "for c in CLASSES:\n",
    "    print(f\" {c}: {total_detections.get(c,0)} detecciones, {len(unique_tracks.get(c,set()))} tracks únicos\")\n",
    "print(\"Vídeo anotado guardado por Ultralytics en la carpeta:\", PROJECT, \"/\", NAME)\n",
    "print(\"CSV:\", CSV_OUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a077436",
   "metadata": {},
   "source": [
    "## Resultados del detector de personas y vehículos\n",
    "\n",
    "Después de procesar todo el vídeo, se presentan los resultados en términos de detecciones y tracks únicos por clase (`bicycle`, `person`, `car`, `bus`).  \n",
    "\n",
    "La salida de la ejecución de la celda da:\n",
    "\n",
    "```text\n",
    "bicycle: 49 detecciones, 3 tracks únicos\n",
    "person: 3387 detecciones, 48 tracks únicos\n",
    "car: 21841 detecciones, 250 tracks únicos\n",
    "bus: 221 detecciones, 9 tracks únicos\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc3bd63",
   "metadata": {},
   "source": [
    "# 2. Detector de matrículas\n",
    "\n",
    "Para poder extraer información de las matrículas de los vehículos, primero es necesario localizarlas en el vídeo. Para ello se utiliza un modelo YOLO entrenado específicamente para detectar la clase `plate`.  \n",
    "\n",
    "El modelo se configura para procesar únicamente la clase de interés, y se realiza un seguimiento de cada matrícula para registrar sus coordenadas y nivel de confianza en un CSV. A medida que se procesan los fotogramas, cada detección se asigna a un identificador que permite localizar la misma matrícula a lo largo del vídeo.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcc414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "VIDEO_IN = \"videos/C0142.mp4\"\n",
    "PROJECT = \"outputs\"\n",
    "NAME = \"C0142_annotated\"\n",
    "CSV_OUT = \"C0142_plate_tracks.csv\"\n",
    "\n",
    "MODEL_WEIGHTS = \"best.pt\"\n",
    "TRACKER_CFG = \"botsort.yaml\"\n",
    "CONF_THRESH = 0.25\n",
    "CLASSES = {\"plate\"}\n",
    "\n",
    "model = YOLO(MODEL_WEIGHTS)\n",
    "\n",
    "id2name = model.names\n",
    "name2id = {v: k for k, v in id2name.items()}\n",
    "\n",
    "desired_class_ids = set()\n",
    "for cls_name in CLASSES:\n",
    "    if cls_name in name2id:\n",
    "        desired_class_ids.add(int(name2id[cls_name]))\n",
    "    else:\n",
    "        print(f\"!! Clase '{cls_name}' no encontrada en model.names.\")\n",
    "\n",
    "print(\"IDs filtrados (clase -> id):\", {id2name[i]: i for i in desired_class_ids})\n",
    "\n",
    "with open(CSV_OUT, \"w\", newline=\"\", encoding=\"utf-8\") as csv_f:\n",
    "    csv_writer = csv.writer(csv_f)\n",
    "    csv_writer.writerow([\"fotograma\", \"tipo_objeto\", \"confianza\", \"identificador_tracking\", \"x1\", \"y1\", \"x2\", \"y2\"])\n",
    "\n",
    "    frame_idx = 0\n",
    "\n",
    "    stream = model.track(\n",
    "        source=VIDEO_IN,\n",
    "        tracker=TRACKER_CFG,\n",
    "        persist=True,\n",
    "        stream=True,\n",
    "        save=True,\n",
    "        project=PROJECT,\n",
    "        name=NAME\n",
    "    )\n",
    "\n",
    "    # métricas\n",
    "    total_detections = {k: 0 for k in CLASSES}\n",
    "    unique_tracks = {k: set() for k in CLASSES}\n",
    "\n",
    "    for results in stream:\n",
    "        frame_idx += 1\n",
    "\n",
    "        boxes = results.boxes\n",
    "        xyxy = boxes.xyxy.cpu().numpy()                 # shape (N,4)\n",
    "        confs = boxes.conf.cpu().numpy()                # shape (N,)\n",
    "        cls_ids = boxes.cls.cpu().numpy().astype(int)   # shape (N,)\n",
    "        if boxes.id is None:\n",
    "            continue\n",
    "        ids = boxes.id.cpu().numpy().astype(int)        # shape (N,)\n",
    "\n",
    "        # Por si acaso trabajamos con el mínimo común\n",
    "        n = min(xyxy.shape[0], confs.shape[0], cls_ids.shape[0], ids.shape[0])\n",
    "\n",
    "        for i in range(n):\n",
    "            conf = float(confs[i])\n",
    "            if conf < CONF_THRESH:\n",
    "                continue\n",
    "\n",
    "            cls_id = int(cls_ids[i])\n",
    "            # filtrar id\n",
    "            if cls_id not in desired_class_ids:\n",
    "                continue\n",
    "\n",
    "            cls_name = id2name[cls_id]\n",
    "            track_id = int(ids[i])\n",
    "            x1, y1, x2, y2 = map(int, xyxy[i])\n",
    "            identifier = f\"{cls_name}_{track_id}\" if track_id >= 0 else f\"{cls_name}_-1\"\n",
    "\n",
    "            csv_writer.writerow([frame_idx, cls_name, f\"{conf:.4f}\", identifier, x1, y1, x2, y2])\n",
    "\n",
    "            total_detections[cls_name] = total_detections.get(cls_name, 0) + 1\n",
    "            if track_id >= 0:\n",
    "                unique_tracks[cls_name].add(track_id)\n",
    "\n",
    "print(\"----- RESUMEN -----\")\n",
    "for c in CLASSES:\n",
    "    print(f\"{c}: {total_detections.get(c,0)} detecciones, {len(unique_tracks.get(c,set()))} tracks únicos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6c34b6",
   "metadata": {},
   "source": [
    "# 3. Comparativa de OCRs\n",
    "\n",
    "Para determinar qué modelo de OCR es más adecuado para reconocer matrículas, se realiza una comparativa entre EasyOCR y PaddleOCR. Se procesan imágenes recortadas de matrículas previamente detectadas y se normaliza el texto para eliminar espacios y caracteres no deseados.  \n",
    "\n",
    "Cada OCR predice el texto de la matrícula y se calcula la precisión utilizando la distancia de Levenshtein entre la matrícula real y la predicción obtenida. Además, se registra el tiempo de inferencia de cada modelo.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42157405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "import re\n",
    "from typing import Tuple\n",
    "\n",
    "import easyocr\n",
    "from paddleocr import PaddleOCR\n",
    "\n",
    "def normalize_plate(s: str) -> str:\n",
    "    \"\"\"\n",
    "    Normaliza el texto de matrícula:\n",
    "    - .strip()\n",
    "    - elimina espacios\n",
    "    - deja solo letras y dígitos\n",
    "    - pasa a mayúsculas\n",
    "    \"\"\"\n",
    "    if s is None:\n",
    "        return ''\n",
    "    s = s.strip()\n",
    "    # eliminar todo lo que NO sea letra o dígito\n",
    "    s = re.sub(r'[^A-Za-z0-9]+', '', s)\n",
    "    return s.upper()\n",
    "\n",
    "def levenshtein(a: str, b: str) -> int:\n",
    "    \"\"\"Distancia de Levenshtein (implementación iterativa).\"\"\"\n",
    "    if a == b:\n",
    "        return 0\n",
    "    la, lb = len(a), len(b)\n",
    "    if la == 0:\n",
    "        return lb\n",
    "    if lb == 0:\n",
    "        return la\n",
    "    # usar solo dos filas para memoria\n",
    "    prev = list(range(lb + 1))\n",
    "    cur = [0] * (lb + 1)\n",
    "    for i in range(1, la + 1):\n",
    "        cur[0] = i\n",
    "        for j in range(1, lb + 1):\n",
    "            cost = 0 if a[i - 1] == b[j - 1] else 1\n",
    "            cur[j] = min(prev[j] + 1,          # borrado\n",
    "                         cur[j - 1] + 1,       # inserción\n",
    "                         prev[j - 1] + cost)   # sustitución\n",
    "        prev, cur = cur, prev\n",
    "    return prev[lb]\n",
    "\n",
    "def accuracy_from_distance(true: str, pred: str) -> float:\n",
    "    \"\"\"\n",
    "    Calcula una tasa de acierto en [0.0, 1.0] a partir de la distancia\n",
    "    de Levenshtein normalizada por la longitud máxima entre true y pred.\n",
    "    \"\"\"\n",
    "    t = normalize_plate(true)\n",
    "    p = normalize_plate(pred)\n",
    "    maxlen = max(len(t), len(p))\n",
    "    if maxlen == 0:\n",
    "        return 0.0\n",
    "    dist = levenshtein(t, p)\n",
    "    acc = max(0.0, 1.0 - (dist / maxlen))\n",
    "    return acc\n",
    "\n",
    "# ----\n",
    "\n",
    "IMAGES_DIR = 'plates-images'\n",
    "OUTPUT_CSV = 'plates_ocr_results.csv'\n",
    "\n",
    "easy_reader = easyocr.Reader(['en'], gpu=False)\n",
    "paddle = PaddleOCR(use_angle_cls=True, lang='en')\n",
    "\n",
    "with open(OUTPUT_CSV, 'w', newline='', encoding='utf-8') as fcsv:\n",
    "    writer = csv.writer(fcsv)\n",
    "    writer.writerow([\n",
    "        'plate_number',\n",
    "        'easyocr_predict',\n",
    "        'easyocr_accuracy',\n",
    "        'easyocr_time',\n",
    "        'paddleocr_predict',\n",
    "        'paddle_accuracy',\n",
    "        'paddle_time'\n",
    "    ])\n",
    "\n",
    "    files = sorted(os.listdir(IMAGES_DIR))\n",
    "    for fname in files:\n",
    "        img_path = os.path.join(IMAGES_DIR, fname)\n",
    "        plate_true = os.path.splitext(fname)[0]\n",
    "\n",
    "        t0 = time.time()\n",
    "        res_easy = easy_reader.readtext(img_path)   # lista de (bbox, text, prob)\n",
    "        easy_time = time.time() - t0\n",
    "\n",
    "        # (bbox, text, prob)\n",
    "        easy_pred_raw = ''.join([t for (_, t, _) in res_easy]) if res_easy else ''\n",
    "        easy_pred = normalize_plate(easy_pred_raw)\n",
    "\n",
    "        print(f\"[easyocr]: '{easy_pred}' tiempo: {easy_time:.3f}s\")\n",
    "\n",
    "\n",
    "        t0 = time.time()\n",
    "        paddle_res0 = paddle.predict(img_path)[0]\n",
    "        paddle_time = time.time() - t0\n",
    "\n",
    "        rec_texts = paddle_res0.get('rec_texts', [])\n",
    "\n",
    "        paddle_pred_raw = ''.join(rec_texts) if rec_texts else ''\n",
    "        paddle_pred = normalize_plate(paddle_pred_raw)\n",
    "        print(f\"[paddleocr]: '{paddle_pred}' tiempo: {paddle_time:.3f}s\\n\")\n",
    "\n",
    "        easy_acc = accuracy_from_distance(plate_true, easy_pred)\n",
    "        paddle_acc = accuracy_from_distance(plate_true, paddle_pred)\n",
    "\n",
    "        writer.writerow([\n",
    "            plate_true,\n",
    "            easy_pred,\n",
    "            f\"{easy_acc:.4f}\",\n",
    "            f\"{easy_time:.4f}\",\n",
    "            paddle_pred,\n",
    "            f\"{paddle_acc:.4f}\",\n",
    "            f\"{paddle_time:.4f}\"\n",
    "        ])\n",
    "\n",
    "print(f\"CSV guardado en: {OUTPUT_CSV}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141d4167",
   "metadata": {},
   "source": [
    "# 3.1 Extracción de matrículas en vídeo de ejemplo\n",
    "\n",
    "Para obtener las matrículas directamente desde el vídeo, se combinan los resultados del detector de matrículas con OCR. Se carga el vídeo y las coordenadas de las matrículas detectadas previamente, y se recorta la región de interés correspondiente a cada placa en cada fotograma.  \n",
    "\n",
    "A continuación, se aplica EasyOCR para reconocer el texto de la matrícula, registrando la confianza de la predicción, el tiempo de procesamiento y el identificador de seguimiento en un archivo CSV.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5771840e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import csv\n",
    "import time\n",
    "import easyocr\n",
    "\n",
    "\n",
    "VIDEO_PATH = \"videos/C0142.mp4\"\n",
    "CSV_PATH = \"C0142_plate_tracks.csv\"\n",
    "OUTPUT_CSV = \"C0142_plates_detected.csv\"\n",
    "\n",
    "\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "\n",
    "detections = []\n",
    "with open(CSV_PATH, newline='', encoding='utf-8') as f:\n",
    "    reader_csv = csv.DictReader(f)\n",
    "    for row in reader_csv:\n",
    "        row['fotograma'] = int(row['fotograma'])\n",
    "        row['x1'] = int(row['x1'])\n",
    "        row['y1'] = int(row['y1'])\n",
    "        row['x2'] = int(row['x2'])\n",
    "        row['y2'] = int(row['y2'])\n",
    "        detections.append(row)\n",
    "\n",
    "detections.sort(key=lambda x: x['fotograma'])\n",
    "\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"No se pudo abrir el video.\")\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(f\"Video abierto ({total_frames} frames, {fps:.2f} fps)\\n\")\n",
    "\n",
    "procesadas = set()\n",
    "resultados = []\n",
    "\n",
    "for det in detections:\n",
    "    frame_num = det['fotograma']\n",
    "    track_id = det['identificador_tracking']\n",
    "    x1, y1, x2, y2 = det['x1'], det['y1'], det['x2'], det['y2']\n",
    "\n",
    "    if track_id in procesadas:\n",
    "        continue\n",
    "\n",
    "    procesadas.add(track_id)\n",
    "    print(f\"\\n Nueva matrícula detectada: {track_id} (frame {frame_num})\")\n",
    "\n",
    "    # Ir al frame indicado\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(f\"!! No se pudo leer el frame {frame_num}\")\n",
    "        continue\n",
    "\n",
    "    h, w = frame.shape[:2]\n",
    "    x1, y1 = max(0, x1), max(0, y1)\n",
    "    x2, y2 = min(w - 1, x2), min(h - 1, y2)\n",
    "    roi = frame[y1:y2, x1:x2]\n",
    "\n",
    "    t0 = time.time()\n",
    "    results = reader.readtext(roi)\n",
    "    ocr_time = time.time() - t0\n",
    "\n",
    "    if results:\n",
    "        # Tomar el texto con mayor probabilidad\n",
    "        best = max(results, key=lambda x: x[2])\n",
    "        text = best[1].strip().replace(\" \", \"\")\n",
    "        prob = best[2]\n",
    "        print(f\"   Texto detectado: '{text}'  (confianza: {prob:.3f}, tiempo: {ocr_time:.3f}s)\")\n",
    "    else:\n",
    "        text = \"\"\n",
    "        prob = 0.0\n",
    "        print(f\"   No se detectó texto. Tiempo: {ocr_time:.3f}s\")\n",
    "\n",
    "    resultados.append({\n",
    "        \"identificador_tracking\": track_id,\n",
    "        \"frame\": frame_num,\n",
    "        \"texto\": text,\n",
    "        \"confianza\": prob,\n",
    "        \"tiempo\": ocr_time\n",
    "    })\n",
    "\n",
    "cap.release()\n",
    "\n",
    "with open(OUTPUT_CSV, 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=[\"identificador_tracking\", \"frame\", \"texto\", \"confianza\", \"tiempo\"])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(resultados)\n",
    "\n",
    "print(f\"\\nProcesamiento finalizado. Resultados guardados en: {OUTPUT_CSV}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
